{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU & GPU Approach:\n",
    "\n",
    "The typical computation process is sequential i.e. task are assigned in queues and it is surved according to its arrival order LIFO. The normal core CPU can compute its fastly but the limitation of this approach is that it serves other process after completing the ones it sees first and CPU has limited numbers of threads. On the other hand GPU has handrads/thousands of thread that can compute parrallely. The following workflow will give more insight:\n",
    "\n",
    "**CPU approach:**\n",
    "\n",
    "<img src=\"https://github.com/hamzafar/GPU_Computation/blob/master/images/sequential%20programming.PNG?raw=true\">\n",
    "\n",
    "\n",
    "**GPU approach:**\n",
    "\n",
    "<img src='https://github.com/hamzafar/GPU_Computation/blob/master/images/GPU%20procesing.PNG?raw=true', width = '600'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance \n",
    "\n",
    "To validate above we have compared the performance between sequential programming (CPU) and parallel programming (GPU) in terms of time.\n",
    "\n",
    "Random data is generated and then simply multiplied using simple approach (for loop) and same data is multiplied on GPU in tensorflow multipy function.\n",
    "\n",
    "The results shows that with simple arithmetic operations GPU outperformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of rows to be multiplied\n",
    "N = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random data genrated for multiplication with different seed\n",
    "np.random.seed(10)\n",
    "df = np.random.randn(N)\n",
    "\n",
    "np.random.seed(100)\n",
    "fms = np.random.randn(N)\n",
    "\n",
    "np.random.seed(1000)\n",
    "gff = np.random.randn(N)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "\n",
    "np.random.seed(10000)\n",
    "cof = np.random.randn(N)\n",
    "\n",
    "pof = np.ndarray(N)\n",
    "risk = np.ndarray(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sequential Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07700443267822266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# determine the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# multiply each of the variable\n",
    "for i in range(0, len(cof)):\n",
    "    pof[i] = df[i] * fms[i] * gff[i]\n",
    "\n",
    "for i in range(0, len(pof)):\n",
    "    risk[i] = pof[i] * cof[i]\n",
    "# find out the runtime\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parallel Programing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# place data to tensors\n",
    "t_df = tf.constant(df, name= 'df')\n",
    "t_fms = tf.constant(fms, name= 'fms')\n",
    "t_gff = tf.constant(gff, name= 'gff')\n",
    "t_cof = tf.constant(cof, name= 'cof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multiply tensors\n",
    "t_pof = tf.multiply(tf.multiply(t_df, t_fms), t_gff , name='pof')\n",
    "t_risk = tf.multiply(t_pof, t_cof, name='cof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start tensorflow session\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.026001453399658203 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# determine the start time\n",
    "start_time = time.time()\n",
    "\n",
    "sess.run(t_risk)\n",
    "# find out the runtime\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution:\n",
    "\n",
    "On board appraoch we will read data from the Data Base to GPU in vector/Matrix form. These Vectors have n number of rows; each row in the tensor(vector/matrix) is assign to specific thread in GPU. \n",
    "\n",
    "There might be scanrios where we need to compute different subset of data, so we will break the data according to given condition and these subsets will be computed parrallelrly. The approach is shown below:\n",
    "\n",
    "<img src= 'https://github.com/hamzafar/GPU_Computation/blob/master/images/tensor.PNG?raw=true', width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graph\n",
    "\n",
    "The cool thing about this approach, visualization graph in which we can validate computation algorithm.\n",
    "\n",
    "Our Multiplication algorithm is shown at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<stripped 400000 bytes>' has type <class 'str'>, but expected one of: ((<class 'bytes'>,),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3b4e1cbf9f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-1e9a7afaef4c>\u001b[0m in \u001b[0;36mshow_graph\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'as_graph_def'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mstrip_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrip_consts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_const_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     code = \"\"\"\n\u001b[1;32m     20\u001b[0m         \u001b[1;33m<\u001b[0m\u001b[0mscript\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1e9a7afaef4c>\u001b[0m in \u001b[0;36mstrip_consts\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<stripped %d bytes>\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mfield_setter\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[1;31m# Testing the value for truthiness captures all of the proto3 defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[1;31m# (0, 0.0, enum 0, and False).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0mnew_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclear_when_set_to_default\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\u001b[0m in \u001b[0;36mCheckValue\u001b[0;34m(self, proposed_value)\u001b[0m\n\u001b[1;32m    107\u001b[0m       message = ('%.1024r has type %s, but expected one of: %s' %\n\u001b[1;32m    108\u001b[0m                  (proposed_value, type(proposed_value), self._acceptable_types))\n\u001b[0;32m--> 109\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproposed_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<stripped 400000 bytes>' has type <class 'str'>, but expected one of: ((<class 'bytes'>,),)"
     ]
    }
   ],
   "source": [
    "show_graph(sess.graph)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
